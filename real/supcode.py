import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity

# =======================
# 1Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# =======================
train_df = pd.read_csv("real/train.csv")
test_df = pd.read_csv("real/test.csv")

y = np.log1p(train_df['SalePrice'])  # üîπ Log-transform target
X = train_df.drop(columns=['SalePrice', 'Id'])
test_ids = test_df['Id']
X_test = test_df.drop(columns=['Id'])

# ‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()

# =======================
# 2Ô∏è‚É£ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing values
# =======================
for c in numeric_cols:
    X[c] = X[c].fillna(X[c].median())
    X_test[c] = X_test[c].fillna(X[c].median())

for c in categorical_cols:
    fill_val = X[c].mode()[0] if not X[c].mode().empty else "Missing"
    X[c] = X[c].fillna(fill_val)
    X_test[c] = X_test[c].fillna(fill_val)

# =======================
# 3Ô∏è‚É£ One-hot encode
# =======================
X_all = pd.concat([X, X_test])
X_all_encoded = pd.get_dummies(X_all, drop_first=True)

# ‡πÅ‡∏¢‡∏Å‡∏Å‡∏•‡∏±‡∏ö train/test
X_encoded = X_all_encoded.iloc[:len(X), :]
X_test_encoded = X_all_encoded.iloc[len(X):, :]

# =======================
# 4Ô∏è‚É£ Scaling numeric features
# =======================
scaler = StandardScaler()
X_encoded[numeric_cols] = scaler.fit_transform(X_encoded[numeric_cols])
X_test_encoded[numeric_cols] = scaler.transform(X_test_encoded[numeric_cols])

# =======================
# 5Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Linear Regression
# =======================
model = LinearRegression()
model.fit(X_encoded, y)

# =======================
# 6Ô∏è‚É£ ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô‡πÉ‡∏ô test.csv
# =======================
y_pred_log = model.predict(X_test_encoded)
y_pred = np.expm1(y_pred_log)  # üîπ ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å log

# =======================
# 7Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå submission
# =======================
submission = pd.DataFrame({'Id': test_ids, 'SalePrice': y_pred})
submission.to_csv("real/my_submission_log.csv", index=False)
print("‚úÖ Saved submission as my_submission_log.csv")
print(f"Predicted range: ${y_pred.min():,.0f} ‚Äì ${y_pred.max():,.0f}")


# =======================
# 8Ô∏è‚É£ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
# =======================
def predict_from_input(user_input: dict):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô‡∏à‡∏≤‡∏Å input ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
    user_input: dictionary ‡πÄ‡∏ä‡πà‡∏ô
    {
        'OverallQual': 7,
        'GrLivArea': 1800,
        'GarageCars': 2,
        'TotalBsmtSF': 900,
        'FullBath': 2,
        'YearBuilt': 2005,
        'Neighborhood': 'CollgCr'
    }
    """

    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame
    user_df = pd.DataFrame([user_input])

    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ missing ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö
    for c in numeric_cols:
        if c not in user_df.columns:
            user_df[c] = X[c].median()
    for c in categorical_cols:
        if c not in user_df.columns:
            user_df[c] = X[c].mode()[0]

    # One-hot encode ‡πÅ‡∏•‡∏∞ align columns ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
    user_encoded = pd.get_dummies(user_df, drop_first=True)
    user_encoded = user_encoded.reindex(columns=X_encoded.columns, fill_value=0)

    # Scaling ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    user_encoded[numeric_cols] = scaler.transform(user_encoded[numeric_cols])

    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ö‡πâ‡∏≤‡∏ô
    user_pred_log = model.predict(user_encoded)
    user_pred = np.expm1(user_pred_log)

    # ‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á (optional)
    # similarity = cosine_similarity(user_encoded, X_encoded).flatten()
    # most_similar_idx = np.argmax(similarity)
    # similar_price = np.expm1(y.iloc[most_similar_idx])

    print(f"\nüè† Predicted Price: ${user_pred[0]:,.2f}")
    # print(f"üîπ Most Similar House Price: ${similar_price:,.2f}")
    # print(f"üîπ Similarity Score: {similarity[most_similar_idx]:.4f}")

    return user_pred[0]


# =======================
# üîπ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
# =======================
example_input = {
    'MSSubClass': 60,
    'LotFrontage': 80,
    'LotArea': 200,
    'OverallQual': 7,
    'OverallCond': 5,
    'YearBuilt': 2000,
    'YearRemodAdd': 2003,
    'Neighborhood': 'CollgCr',
    'BldgType': '1Fam',
    'HouseStyle': '2Story',
    'Exterior1st': 'VinylSd',
    'Exterior2nd': 'VinylSd',
    'ExterQual': 'Gd',
    'ExterCond': 'TA',
    'Foundation': 'PConc',
    'BsmtQual': 'Gd',
    'BsmtCond': 'TA',
    'Heating': 'GasA',
    'HeatingQC': 'Ex',
    'CentralAir': 'Y',
    'KitchenQual': 'Gd',
    'Functional': 'Typ',
    'Fireplaces': 1,
    'GarageCars': 2,
    'GarageArea': 500
}

predict_from_input(example_input)
